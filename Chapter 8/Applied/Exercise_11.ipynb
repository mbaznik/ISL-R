{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Use Caravan data set to compare results of boosting vs. other approaches.\n",
    "rm(list=ls())\n",
    "library(ISLR)      # Caravan dset\n",
    "library(gbm)       # Boosting\n",
    "library(class)     # knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  No  Yes \n",
       "5474  348 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1000\n",
      "[1] 4822\n",
      "[1] 5822\n"
     ]
    }
   ],
   "source": [
    "# Part a: Create train set of first 1,000 obs, test set of rest:\n",
    "# Create a binary version of Purchase, and drop Purchase (since gbm requires 0/1):\n",
    "table(Caravan$Purchase)\n",
    "Caravan$Purchase_bin <- ifelse(Caravan$Purchase=='Yes', 1, 0)\n",
    "Caravan_clean        <- subset(Caravan, select=-c(Purchase))\n",
    "fix(Caravan_clean)\n",
    "num_row     <- nrow(Caravan_clean)\n",
    "train       <- Caravan_clean[1:1000,]\n",
    "test        <- Caravan_clean[1001:num_row,]\n",
    "print(nrow(train)); print(nrow(test)); print(num_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   0 \n",
       "1000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   0 \n",
       "1000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# When I try to fit the below gbm, it tells me the below 2 features do not have\n",
    "# any variation.  Here, I confirm that and then exclude them from train and test.\n",
    "table(train$PVRAAUT)\n",
    "table(train$AVRAAUT)\n",
    "# Exclude both:\n",
    "train_clean <- subset(train, select = -c(PVRAAUT,AVRAAUT))\n",
    "test_clean  <- subset(test,  select = -c(PVRAAUT,AVRAAUT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              var  rel.inf\n",
      "PPERSAUT PPERSAUT 7.480819\n",
      "MOPLHOOG MOPLHOOG 4.882054\n",
      "MGODGE     MGODGE 4.838870\n",
      "MKOOPKLA MKOOPKLA 4.507280\n",
      "MOSTYPE   MOSTYPE 3.902338\n",
      "MGODPR     MGODPR 3.547892\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAzFBMVEUAAAAAAP8AA/8ABv8A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\nCQIICQL8f0NpOorufvUqAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      },
      "text/plain": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part b: Fit a boosted model to the train set:\n",
    "set.seed(1)\n",
    "# Parms:\n",
    "num_trees <- 1000\n",
    "shrinkage <- 0.01\n",
    "# Fit model:\n",
    "boost.mod <- gbm(Purchase_bin~., data=train_clean, n.trees=num_trees, distribution=\"bernoulli\",\n",
    "                    interaction.depth=4, shrinkage=shrinkage)\n",
    "print(head(summary(boost.mod)))\n",
    "# Clearly PPERSAUT is the most important variable, followed distantly by \n",
    "# MOPLHOOG, MGODGE, and MKOOPKLA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n",
       "0.002184 0.009556 0.018223 0.048722 0.046377 0.951933 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          \n",
      "              0    1\n",
      "  Pred_No  4336  258\n",
      "  Pred_Yes  197   31\n",
      "[1] 0.136\n"
     ]
    }
   ],
   "source": [
    "# Part c: \n",
    "# Predict the prob of a person making a purchase:\n",
    "boost.mod.pred           <- predict(boost.mod, newdata=test_clean, \n",
    "                                    n.trees=num_trees, type=\"response\")\n",
    "summary(boost.mod.pred)\n",
    "# Predict a person will make a purchase if pred prob>0.2 \n",
    "test_clean$Purchase_pred <- ifelse(boost.mod.pred>0.2, 'Pred_Yes', 'Pred_No')\n",
    "# Form a confusion matrix:\n",
    "conf_mat <- table(test_clean$Purchase_pred, test_clean$Purchase_bin)\n",
    "print(conf_mat)\n",
    "# Compute fraction of people predicted to make a purchase make one:\n",
    "answer <- round(conf_mat[2,2]/sum(conf_mat[2,]),3)\n",
    "print(answer)\n",
    "# 13.6% of those predicted to actually make a purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \n",
      "knn.pred    0    1\n",
      "       0 4513  281\n",
      "       1   20    8\n",
      "[1] 0.286\n"
     ]
    }
   ],
   "source": [
    "# Part c: Continued.\n",
    "# Scale the data before applying KNN:\n",
    "train_clean_scaled <- scale(train_clean[,1:83])  # Don't scale response var\n",
    "test_clean_scaled  <- scale( test_clean[,1:83])  # Don't scale response var\n",
    "# Apply KNN to this data set with arbitrary selection of K=5\n",
    "set.seed(1)\n",
    "knn.pred <- knn(train_clean_scaled, test_clean_scaled, train_clean[,84], k=5)\n",
    "# Form a confusion matrix:\n",
    "conf_mat <- table(knn.pred, test_clean$Purchase_bin)\n",
    "print(conf_mat)\n",
    "# Compute fraction of people predicted to make a purchase make one:\n",
    "answer <- round(conf_mat[2,2]/sum(conf_mat[2,]),3)\n",
    "print(answer)\n",
    "# About 28.6% of predicted purchasers actually made a purchase.\n",
    "# While this is higher than boosted model, clearly it predicts a much smaller\n",
    "# absolute amount will be purchased.  Clearly, a normative decision needs to be\n",
    "# made here to determine what is optimal: maximizing % correctly predicted or \n",
    "# absolute number of correct predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 82</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>MOSTYPE</th><th scope=col>MAANTHUI</th><th scope=col>MGEMOMV</th><th scope=col>MGEMLEEF</th><th scope=col>MOSHOOFD</th><th scope=col>MGODRK</th><th scope=col>MGODPR</th><th scope=col>MGODOV</th><th scope=col>MGODGE</th><th scope=col>MRELGE</th><th scope=col>...</th><th scope=col>ALEVEN</th><th scope=col>APERSONG</th><th scope=col>AGEZONG</th><th scope=col>AWAOREG</th><th scope=col>ABRAND</th><th scope=col>APLEZIER</th><th scope=col>AFIETS</th><th scope=col>AINBOED</th><th scope=col>ABYSTAND</th><th scope=col>Purchase_bin</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>...</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>33</td><td>1</td><td>3</td><td>2</td><td> 8</td><td>0</td><td>5</td><td>1</td><td>3</td><td>7</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>37</td><td>1</td><td>2</td><td>2</td><td> 8</td><td>1</td><td>4</td><td>1</td><td>4</td><td>6</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>37</td><td>1</td><td>2</td><td>2</td><td> 8</td><td>0</td><td>4</td><td>2</td><td>4</td><td>3</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>4</th><td> 9</td><td>1</td><td>3</td><td>3</td><td> 3</td><td>2</td><td>3</td><td>2</td><td>4</td><td>5</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>40</td><td>1</td><td>4</td><td>2</td><td>10</td><td>1</td><td>4</td><td>1</td><td>4</td><td>7</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>23</td><td>1</td><td>2</td><td>1</td><td> 5</td><td>0</td><td>5</td><td>0</td><td>5</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 82\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & MOSTYPE & MAANTHUI & MGEMOMV & MGEMLEEF & MOSHOOFD & MGODRK & MGODPR & MGODOV & MGODGE & MRELGE & ... & ALEVEN & APERSONG & AGEZONG & AWAOREG & ABRAND & APLEZIER & AFIETS & AINBOED & ABYSTAND & Purchase\\_bin\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ... & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 33 & 1 & 3 & 2 &  8 & 0 & 5 & 1 & 3 & 7 & ... & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t2 & 37 & 1 & 2 & 2 &  8 & 1 & 4 & 1 & 4 & 6 & ... & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t3 & 37 & 1 & 2 & 2 &  8 & 0 & 4 & 2 & 4 & 3 & ... & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t4 &  9 & 1 & 3 & 3 &  3 & 2 & 3 & 2 & 4 & 5 & ... & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t5 & 40 & 1 & 4 & 2 & 10 & 1 & 4 & 1 & 4 & 7 & ... & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t6 & 23 & 1 & 2 & 1 &  5 & 0 & 5 & 0 & 5 & 0 & ... & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 82\n",
       "\n",
       "| <!--/--> | MOSTYPE &lt;dbl&gt; | MAANTHUI &lt;dbl&gt; | MGEMOMV &lt;dbl&gt; | MGEMLEEF &lt;dbl&gt; | MOSHOOFD &lt;dbl&gt; | MGODRK &lt;dbl&gt; | MGODPR &lt;dbl&gt; | MGODOV &lt;dbl&gt; | MGODGE &lt;dbl&gt; | MRELGE &lt;dbl&gt; | ... ... | ALEVEN &lt;dbl&gt; | APERSONG &lt;dbl&gt; | AGEZONG &lt;dbl&gt; | AWAOREG &lt;dbl&gt; | ABRAND &lt;dbl&gt; | APLEZIER &lt;dbl&gt; | AFIETS &lt;dbl&gt; | AINBOED &lt;dbl&gt; | ABYSTAND &lt;dbl&gt; | Purchase_bin &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 33 | 1 | 3 | 2 |  8 | 0 | 5 | 1 | 3 | 7 | ... | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 2 | 37 | 1 | 2 | 2 |  8 | 1 | 4 | 1 | 4 | 6 | ... | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 3 | 37 | 1 | 2 | 2 |  8 | 0 | 4 | 2 | 4 | 3 | ... | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 4 |  9 | 1 | 3 | 3 |  3 | 2 | 3 | 2 | 4 | 5 | ... | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 5 | 40 | 1 | 4 | 2 | 10 | 1 | 4 | 1 | 4 | 7 | ... | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 6 | 23 | 1 | 2 | 1 |  5 | 0 | 5 | 0 | 5 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  MOSTYPE MAANTHUI MGEMOMV MGEMLEEF MOSHOOFD MGODRK MGODPR MGODOV MGODGE MRELGE\n",
       "1 33      1        3       2         8       0      5      1      3      7     \n",
       "2 37      1        2       2         8       1      4      1      4      6     \n",
       "3 37      1        2       2         8       0      4      2      4      3     \n",
       "4  9      1        3       3         3       2      3      2      4      5     \n",
       "5 40      1        4       2        10       1      4      1      4      7     \n",
       "6 23      1        2       1         5       0      5      0      5      0     \n",
       "  ... ALEVEN APERSONG AGEZONG AWAOREG ABRAND APLEZIER AFIETS AINBOED ABYSTAND\n",
       "1 ... 0      0        0       0       1      0        0      0       0       \n",
       "2 ... 0      0        0       0       1      0        0      0       0       \n",
       "3 ... 0      0        0       0       1      0        0      0       0       \n",
       "4 ... 0      0        0       0       1      0        0      0       0       \n",
       "5 ... 0      0        0       0       1      0        0      0       0       \n",
       "6 ... 0      0        0       0       0      0        0      0       0       \n",
       "  Purchase_bin\n",
       "1 0           \n",
       "2 0           \n",
       "3 0           \n",
       "4 0           \n",
       "5 0           \n",
       "6 0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Before we can apply logistic regression, I need to first remove two variables which\n",
    "# cause singularity in the estimation matrix:\n",
    "train_cleaner <- subset(train_clean, select = -c(AWERKT,AZEILPL))\n",
    "test_cleaner  <- subset(test_clean,  select = -c(AWERKT,AZEILPL))\n",
    "head(train_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Purchase_bin ~ ., family = binomial, data = train_cleaner)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.5422  -0.3307  -0.1710  -0.0766   3.3780  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)  \n",
       "(Intercept)  2.561e+02  4.912e+04   0.005   0.9958  \n",
       "MOSTYPE     -1.814e-02  1.366e-01  -0.133   0.8944  \n",
       "MAANTHUI     7.131e-02  4.419e-01   0.161   0.8718  \n",
       "MGEMOMV     -9.298e-01  4.201e-01  -2.213   0.0269 *\n",
       "MGEMLEEF     4.187e-02  2.840e-01   0.147   0.8828  \n",
       "MOSHOOFD     1.400e-01  6.127e-01   0.228   0.8193  \n",
       "MGODRK      -7.230e-01  3.571e-01  -2.025   0.0429 *\n",
       "MGODPR      -3.201e-01  3.608e-01  -0.887   0.3750  \n",
       "MGODOV      -6.499e-01  3.221e-01  -2.018   0.0436 *\n",
       "MGODGE      -2.773e-01  3.504e-01  -0.791   0.4287  \n",
       "MRELGE       7.989e-01  4.116e-01   1.941   0.0522 .\n",
       "MRELSA       6.917e-01  3.877e-01   1.784   0.0744 .\n",
       "MRELOV       8.762e-01  4.205e-01   2.084   0.0372 *\n",
       "MFALLEEN    -3.702e-01  3.743e-01  -0.989   0.3227  \n",
       "MFGEKIND    -2.986e-01  3.809e-01  -0.784   0.4331  \n",
       "MFWEKIND    -5.345e-02  4.079e-01  -0.131   0.8957  \n",
       "MOPLHOOG    -4.342e-01  3.924e-01  -1.106   0.2685  \n",
       "MOPLMIDD    -6.936e-01  4.168e-01  -1.664   0.0961 .\n",
       "MOPLLAAG    -5.118e-01  4.168e-01  -1.228   0.2196  \n",
       "MBERHOOG     1.080e-01  2.979e-01   0.363   0.7170  \n",
       "MBERZELF    -2.737e-01  3.246e-01  -0.843   0.3991  \n",
       "MBERBOER    -5.788e-01  3.757e-01  -1.541   0.1234  \n",
       "MBERMIDD     4.193e-01  2.983e-01   1.406   0.1598  \n",
       "MBERARBG     2.787e-01  2.847e-01   0.979   0.3276  \n",
       "MBERARBO     3.511e-01  2.954e-01   1.188   0.2347  \n",
       "MSKA         3.591e-01  2.859e-01   1.256   0.2092  \n",
       "MSKB1        1.434e-01  2.839e-01   0.505   0.6134  \n",
       "MSKB2        1.783e-01  2.516e-01   0.709   0.4785  \n",
       "MSKC         1.093e-01  2.800e-01   0.390   0.6963  \n",
       "MSKD        -3.869e-01  2.930e-01  -1.320   0.1867  \n",
       "MHHUUR      -1.568e+01  3.329e+03  -0.005   0.9962  \n",
       "MHKOOP      -1.561e+01  3.329e+03  -0.005   0.9963  \n",
       "MAUT1        4.233e-01  4.097e-01   1.033   0.3015  \n",
       "MAUT2        4.304e-01  3.733e-01   1.153   0.2489  \n",
       "MAUT0        2.256e-01  3.742e-01   0.603   0.5466  \n",
       "MZFONDS     -1.376e+01  4.325e+03  -0.003   0.9975  \n",
       "MZPART      -1.377e+01  4.325e+03  -0.003   0.9975  \n",
       "MINKM30      1.123e-01  2.957e-01   0.380   0.7041  \n",
       "MINK3045     9.255e-02  2.820e-01   0.328   0.7428  \n",
       "MINK4575     2.606e-01  2.932e-01   0.889   0.3740  \n",
       "MINK7512     3.601e-01  3.083e-01   1.168   0.2427  \n",
       "MINK123M    -1.407e-01  5.046e-01  -0.279   0.7803  \n",
       "MINKGEM     -3.643e-01  2.777e-01  -1.312   0.1896  \n",
       "MKOOPKLA     2.325e-01  1.340e-01   1.735   0.0828 .\n",
       "PWAPART      9.343e-01  9.813e-01   0.952   0.3411  \n",
       "PWABEDR     -9.056e-01  4.221e+03   0.000   0.9998  \n",
       "PWALAND     -1.752e+01  3.513e+03  -0.005   0.9960  \n",
       "PPERSAUT     3.757e-01  1.473e-01   2.550   0.0108 *\n",
       "PBESAUT     -3.792e+01  1.332e+04  -0.003   0.9977  \n",
       "PMOTSCO      2.230e-01  2.466e-01   0.904   0.3659  \n",
       "PAANHANG     1.573e+01  6.805e+03   0.002   0.9982  \n",
       "PTRACTOR    -3.326e-01  1.953e+03   0.000   0.9999  \n",
       "PWERKT       1.676e+01  6.051e+03   0.003   0.9978  \n",
       "PBROM       -1.094e-01  1.334e+00  -0.082   0.9346  \n",
       "PLEVEN       2.405e-01  7.074e-01   0.340   0.7339  \n",
       "PPERSONG     1.269e+00  5.719e+03   0.000   0.9998  \n",
       "PGEZONG      2.000e+01  3.768e+03   0.005   0.9958  \n",
       "PWAOREG      1.452e+01  3.099e+03   0.005   0.9963  \n",
       "PBRAND       3.369e-02  2.188e-01   0.154   0.8776  \n",
       "PZEILPL      3.738e+01  1.205e+04   0.003   0.9975  \n",
       "PPLEZIER     6.371e-01  6.421e-01   0.992   0.3211  \n",
       "PFIETS       2.101e+01  5.469e+03   0.004   0.9969  \n",
       "PINBOED      5.699e-01  3.915e+03   0.000   0.9999  \n",
       "PBYSTAND     4.167e-01  9.550e-01   0.436   0.6626  \n",
       "AWAPART     -1.475e+00  1.938e+00  -0.761   0.4468  \n",
       "AWABEDR     -1.417e+01  8.880e+03  -0.002   0.9987  \n",
       "AWALAND      5.416e+01  1.054e+04   0.005   0.9959  \n",
       "APERSAUT    -6.572e-01  7.374e-01  -0.891   0.3728  \n",
       "ABESAUT      1.730e+02  7.554e+04   0.002   0.9982  \n",
       "AMOTSCO     -1.143e-01  5.805e-01  -0.197   0.8439  \n",
       "AAANHANG    -3.099e+01  1.361e+04  -0.002   0.9982  \n",
       "ATRACTOR    -1.545e+01  6.899e+03  -0.002   0.9982  \n",
       "ABROM       -2.511e-01  4.265e+00  -0.059   0.9531  \n",
       "ALEVEN      -8.600e-01  1.485e+00  -0.579   0.5625  \n",
       "APERSONG    -1.879e+01  1.328e+04  -0.001   0.9989  \n",
       "AGEZONG     -5.763e+01  1.130e+04  -0.005   0.9959  \n",
       "AWAOREG     -3.190e+01  1.360e+04  -0.002   0.9981  \n",
       "ABRAND       5.725e-01  6.981e-01   0.820   0.4122  \n",
       "APLEZIER     1.083e+00  1.712e+00   0.633   0.5268  \n",
       "AFIETS      -1.929e+01  5.469e+03  -0.004   0.9972  \n",
       "AINBOED     -1.979e+01  8.686e+03  -0.002   0.9982  \n",
       "ABYSTAND    -5.835e-03  3.395e+00  -0.002   0.9986  \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 448.41  on 999  degrees of freedom\n",
       "Residual deviance: 320.64  on 918  degrees of freedom\n",
       "AIC: 484.64\n",
       "\n",
       "Number of Fisher Scoring iterations: 18\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          \n",
      "              0    1\n",
      "  Pred_No  4183  231\n",
      "  Pred_Yes  350   58\n",
      "[1] 0.142\n"
     ]
    }
   ],
   "source": [
    "# Part c: Continued again.\n",
    "# Apply logistic regression to this data set:\n",
    "set.seed(1)\n",
    "logis.mod       <- glm(Purchase_bin~., data=train_cleaner, family=binomial)\n",
    "summary(logis.mod)\n",
    "logis.mod.pred  <- predict(logis.mod, newdata=test_cleaner, type=\"response\")\n",
    "# summary(logis.mod)\n",
    "# sort(logis.mod$fitted.values)\n",
    "# There is a warning message that fitted vals close to 0 or 1 occured.\n",
    "# 1 predicted value of 1.0, and multiple predicted\n",
    "# values that are very close to 0.  I don't think that invalidates the fit.\n",
    "# I think the point of this excercise is that logistic regression will not perform\n",
    "# well here, without some sort of variable selection being performed, because of so\n",
    "# many predictor variables.\n",
    "# Predict a person will make a purchase if pred prob>0.2 \n",
    "test_cleaner$Purchase_pred <- ifelse(logis.mod.pred>0.2, 'Pred_Yes', 'Pred_No')\n",
    "# Form a confusion matrix:\n",
    "conf_mat <- table(test_cleaner$Purchase_pred, test_cleaner$Purchase_bin)\n",
    "print(conf_mat)\n",
    "# Compute fraction of people predicted to make a purchase make one:\n",
    "answer <- round(conf_mat[2,2]/sum(conf_mat[2,]),3)\n",
    "print(answer)\n",
    "# About 14.2% of predicted purchasers actually made a purchase.  This is about \n",
    "# close to the boosted model but much less than KNN.  It predicts many more\n",
    "# true postives, but at a lower correct prediction rate.  Again, it goes back to\n",
    "# the question: what trade-offs are we willing to make here?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
