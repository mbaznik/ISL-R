{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 9, Exercise 6\n",
    "# Packages/options:\n",
    "rm(list=ls())\n",
    "# For svm() function\n",
    "library(e1071)\n",
    "# Number of observations:\n",
    "num_obs      <- 10\n",
    "num_obs_test <- 1000\n",
    "# Bandwidth of 1st feature:\n",
    "abs_uni <- 10\n",
    "# Systemic separation to generate x2\n",
    "sys_sep <- 7\n",
    "# Noise standard deviation:\n",
    "nse_sd  <- 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-4.689826737158</li><li>-2.5575220072642</li><li>1.45706726703793</li><li>8.16415579989552</li><li>-5.96636137925088</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -4.689826737158\n",
       "\\item -2.5575220072642\n",
       "\\item 1.45706726703793\n",
       "\\item 8.16415579989552\n",
       "\\item -5.96636137925088\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -4.689826737158\n",
       "2. -2.5575220072642\n",
       "3. 1.45706726703793\n",
       "4. 8.16415579989552\n",
       "5. -5.96636137925088\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -4.689827 -2.557522  1.457067  8.164156 -5.966361"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part a:\n",
    "# Generate a two-class data set with p=2 in a way that the two classes\n",
    "# are just linearly separable:\n",
    "set.seed(1)\n",
    "x1 <- runif(num_obs, min=-abs_uni, max=abs_uni)\n",
    "head(x1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"red\"  \"red\"  \"red\"  \"blue\" \"blue\"\n"
     ]
    }
   ],
   "source": [
    "# Arbitrarily set the first num_obs/2 values of the response variable\n",
    "# equal to red, the rest to blue:\n",
    "cols <- c(rep('red',num_obs/2), rep('blue',num_obs/2))\n",
    "# Inspect to see the switch:\n",
    "begin_view <- num_obs/2-2\n",
    "end_view   <- num_obs/2+2\n",
    "print(cols[begin_view:end_view])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]  1  1  1 -1 -1\n",
      "[1] -4.922810  2.924574  4.429948  3.454688 -1.832330  9.070687\n",
      "[1]  4.077190 11.924574 13.429948 12.454688  7.167670  4.070687\n"
     ]
    }
   ],
   "source": [
    "# I'd like the linear separation to be of the form x2=2,\n",
    "# plus or minus some noise.\n",
    "# Raise up red entries above the divider, allow blue to\n",
    "# sink down below:\n",
    "col_ind <- ifelse(cols=='red', 1, -1)\n",
    "print(col_ind[begin_view:end_view])\n",
    "noise     <- rnorm(num_obs, mean=0, sd=nse_sd)\n",
    "print(head(noise))\n",
    "x2        <- (2+col_ind*sys_sep+noise)\n",
    "print(head(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>cols</th><th scope=col>x1</th><th scope=col>x2</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>red </td><td>-4.689827</td><td> 4.077190</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>red </td><td>-2.557522</td><td>11.924574</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>red </td><td> 1.457067</td><td>13.429948</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>red </td><td> 8.164156</td><td>12.454688</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>red </td><td>-5.966361</td><td> 7.167670</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>blue</td><td> 7.967794</td><td> 4.070687</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & cols & x1 & x2\\\\\n",
       "  & <fct> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & red  & -4.689827 &  4.077190\\\\\n",
       "\t2 & red  & -2.557522 & 11.924574\\\\\n",
       "\t3 & red  &  1.457067 & 13.429948\\\\\n",
       "\t4 & red  &  8.164156 & 12.454688\\\\\n",
       "\t5 & red  & -5.966361 &  7.167670\\\\\n",
       "\t6 & blue &  7.967794 &  4.070687\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 3\n",
       "\n",
       "| <!--/--> | cols &lt;fct&gt; | x1 &lt;dbl&gt; | x2 &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | red  | -4.689827 |  4.077190 |\n",
       "| 2 | red  | -2.557522 | 11.924574 |\n",
       "| 3 | red  |  1.457067 | 13.429948 |\n",
       "| 4 | red  |  8.164156 | 12.454688 |\n",
       "| 5 | red  | -5.966361 |  7.167670 |\n",
       "| 6 | blue |  7.967794 |  4.070687 |\n",
       "\n"
      ],
      "text/plain": [
       "  cols x1        x2       \n",
       "1 red  -4.689827  4.077190\n",
       "2 red  -2.557522 11.924574\n",
       "3 red   1.457067 13.429948\n",
       "4 red   8.164156 12.454688\n",
       "5 red  -5.966361  7.167670\n",
       "6 blue  7.967794  4.070687"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "twoclass_df <- data.frame(cols, x1, x2)\n",
    "head(twoclass_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following objects are masked _by_ .GlobalEnv:\n",
      "\n",
      "    cols, x1, x2\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAAP9NTU1oaGh8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\nGla1+8dlAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      },
      "text/plain": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot:\n",
    "attach(twoclass_df); \n",
    "plot(twoclass_df$x1, twoclass_df$x2, col=c(\"blue\",\"red\")[twoclass_df$cols],\n",
    "    xlab=\"x1\", ylab=\"x2\") \n",
    "detach(twoclass_df)\n",
    "# There is clearly a visible separation between the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  cols        x1        x2  y\n",
      "1  red -4.689827  4.077190  1\n",
      "2  red -2.557522 11.924574  1\n",
      "3  red  1.457067 13.429948  1\n",
      "4  red  8.164156 12.454688  1\n",
      "5  red -5.966361  7.167670  1\n",
      "6 blue  7.967794  4.070687 -1\n",
      "         x1        x2  y\n",
      "1 -4.689827  4.077190  1\n",
      "2 -2.557522 11.924574  1\n",
      "3  1.457067 13.429948  1\n",
      "4  8.164156 12.454688  1\n",
      "5 -5.966361  7.167670  1\n",
      "6  7.967794  4.070687 -1\n"
     ]
    }
   ],
   "source": [
    "# Code Red==1, Blue==-1\n",
    "twoclass_df$y  <- as.factor(ifelse(twoclass_df$cols==\"red\", 1, -1))\n",
    "print(head(twoclass_df))\n",
    "twoclass_clean <- twoclass_df[,-c(1)]\n",
    "print(head(twoclass_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    \n",
       "     -1 1\n",
       "  -1  5 0\n",
       "  1   0 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verify that these two classes are indeed linearly separable\n",
    "# by training a SVC with a very high value of cost.\n",
    "svmfit   <- svm(y~., data=twoclass_clean, kernel=\"linear\", cost=10000)\n",
    "# ls(svmfit)\n",
    "table(svmfit$fitted, twoclass_clean$y)\n",
    "# Clearly, the above SVC predicts all obs correctly on the train data, and thus\n",
    "# this two feature, two class data is linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Parameter tuning of 'svm':\n",
       "\n",
       "- sampling method: leave-one-out \n",
       "\n",
       "- best parameters:\n",
       " cost\n",
       "   10\n",
       "\n",
       "- best performance: 0.3 \n",
       "\n",
       "- Detailed performance results:\n",
       "   cost error dispersion\n",
       "1 1e-03   1.0  0.0000000\n",
       "2 1e-02   1.0  0.0000000\n",
       "3 1e-01   0.5  0.5270463\n",
       "4 1e+01   0.3  0.4830459\n",
       "5 1e+02   0.3  0.4830459\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part b:\n",
    "# Compute CV error rates for SVCs with different values of the cost parm:\n",
    "set.seed(1)\n",
    "tune.out <- tune(svm, y~., data=twoclass_clean, kernel=\"linear\", \n",
    "                 ranges=list(cost=c(0.001, 0.01, 0.1, 10, 100)))\n",
    "summary(tune.out)\n",
    "# ls(tune.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 2 2 2 1 0\n",
      "[1] 0.2 0.2 0.2 0.1 0.0\n"
     ]
    }
   ],
   "source": [
    "# Compute train errors for each value of cost:\n",
    "cost_vec <- c(0.001, 0.01, 0.1, 10, 100)\n",
    "misclass <- rep(0, length(cost_vec))\n",
    "set.seed(1)\n",
    "for (i in 1:length(cost_vec))\n",
    "{\n",
    "    svmfit_temp <- svm(y~., data=twoclass_clean, kernel=\"linear\", cost=cost_vec[i])\n",
    "    conf_matrix <- table(svmfit_temp$fitted, twoclass_clean$y)\n",
    "    misclass[i] <- (conf_matrix[2,1]+conf_matrix[1,2])\n",
    "    \n",
    "}\n",
    "misclass_rt <- misclass/nrow(twoclass_clean)\n",
    "print(misclass)\n",
    "print(misclass_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAAP9NTU1oaGh8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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      },
      "text/plain": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The number of train errors obtained for each value of cost is above.\n",
    "# This roughly aligns with the CV indications: namely both train error and CV indicate\n",
    "# that a higher value of the cost parm is better.\n",
    "cost_vec_log10 <- log10(cost_vec)\n",
    "plot(cost_vec_log10, tune.out$performances[,2], xlab=\"log10 of cost_vec\",\n",
    "    ylab=\"Error\", pch=19, type=\"b\", ylim=c(0,1), col=\"red\")\n",
    "lines(cost_vec_log10, misclass_rt, pch=18, type=\"b\", col=\"blue\")\n",
    "legend(\"topright\", legend=c(\"CV_Error\", \"Train_Error\"), col=c(\"red\", \"blue\"), lty=1:2, cex=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]  4.077190 11.924574 13.429948 12.454688  7.167670  4.070687\n"
     ]
    }
   ],
   "source": [
    "# Part c:\n",
    "# Generate an appropriate test data set:\n",
    "set.seed(2)\n",
    "# Define x1:\n",
    "x1 <- runif(num_obs_test, min=-abs_uni, max=abs_uni)\n",
    "# Define y:\n",
    "test_cols <- c(rep('red',num_obs_test/2), rep('blue',num_obs_test/2))\n",
    "# Define x2:\n",
    "test_col_ind <- ifelse(test_cols=='red', 1, -1)\n",
    "test_noise   <- rnorm(num_obs_test, mean=0, sd=nse_sd)\n",
    "x2        <- (2+col_ind*sys_sep+noise)\n",
    "print(head(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>test_cols</th><th scope=col>x1</th><th scope=col>x2</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>red</td><td>-6.302355</td><td> 4.077190</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>red</td><td> 4.047481</td><td>11.924574</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>red</td><td> 1.466527</td><td>13.429948</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>red</td><td>-6.638962</td><td>12.454688</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>red</td><td> 8.876787</td><td> 7.167670</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>red</td><td> 8.869499</td><td> 4.070687</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & test\\_cols & x1 & x2\\\\\n",
       "  & <fct> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & red & -6.302355 &  4.077190\\\\\n",
       "\t2 & red &  4.047481 & 11.924574\\\\\n",
       "\t3 & red &  1.466527 & 13.429948\\\\\n",
       "\t4 & red & -6.638962 & 12.454688\\\\\n",
       "\t5 & red &  8.876787 &  7.167670\\\\\n",
       "\t6 & red &  8.869499 &  4.070687\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 3\n",
       "\n",
       "| <!--/--> | test_cols &lt;fct&gt; | x1 &lt;dbl&gt; | x2 &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | red | -6.302355 |  4.077190 |\n",
       "| 2 | red |  4.047481 | 11.924574 |\n",
       "| 3 | red |  1.466527 | 13.429948 |\n",
       "| 4 | red | -6.638962 | 12.454688 |\n",
       "| 5 | red |  8.876787 |  7.167670 |\n",
       "| 6 | red |  8.869499 |  4.070687 |\n",
       "\n"
      ],
      "text/plain": [
       "  test_cols x1        x2       \n",
       "1 red       -6.302355  4.077190\n",
       "2 red        4.047481 11.924574\n",
       "3 red        1.466527 13.429948\n",
       "4 red       -6.638962 12.454688\n",
       "5 red        8.876787  7.167670\n",
       "6 red        8.869499  4.070687"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test_cols        x1        x2 y\n",
      "1       red -6.302355  4.077190 1\n",
      "2       red  4.047481 11.924574 1\n",
      "3       red  1.466527 13.429948 1\n",
      "4       red -6.638962 12.454688 1\n",
      "5       red  8.876787  7.167670 1\n",
      "6       red  8.869499  4.070687 1\n",
      "         x1        x2 y\n",
      "1 -6.302355  4.077190 1\n",
      "2  4.047481 11.924574 1\n",
      "3  1.466527 13.429948 1\n",
      "4 -6.638962 12.454688 1\n",
      "5  8.876787  7.167670 1\n",
      "6  8.869499  4.070687 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "1000"
      ],
      "text/latex": [
       "1000"
      ],
      "text/markdown": [
       "1000"
      ],
      "text/plain": [
       "[1] 1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "twoclass_df_test <- data.frame(test_cols, x1, x2)\n",
    "head(twoclass_df_test)\n",
    "twoclass_df_test$y  <- as.factor(ifelse(twoclass_df_test$test_cols==\"red\", 1, -1))\n",
    "print(head(twoclass_df_test))\n",
    "twoclass_clean_test <- twoclass_df_test[,-c(1)]\n",
    "print(head(twoclass_clean_test))\n",
    "nrow(twoclass_clean_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.496 0.496 0.497 0.497 0.515\n"
     ]
    }
   ],
   "source": [
    "# Compute test errors for each value of cost:\n",
    "misclass_test <- rep(0, length(cost_vec))\n",
    "set.seed(1)\n",
    "for (i in 1:length(cost_vec))\n",
    "{\n",
    "    svmfit_temp <- svm(y~., data=twoclass_clean, kernel=\"linear\", cost=cost_vec[i])\n",
    "    preds_temp  <- predict(svmfit_temp, newdata=twoclass_clean_test)\n",
    "    conf_matrix_test <- table(preds_temp, twoclass_clean_test$y)\n",
    "    misclass_test[i] <- (conf_matrix_test[2,1]+conf_matrix_test[1,2])\n",
    "    \n",
    "}\n",
    "misclass_test_rt <- misclass_test/nrow(twoclass_clean_test)\n",
    "print(head(misclass_test_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearly cost values of 10^-3 and 10^-2 yield the lowest error rate on a test set.\n",
    "# This disagrees with the indication from CV on training set (which indicated 10^1 and 10^2),\n",
    "# and also disagrees with the indication from the training error set which indicated 10^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part d:\n",
    "# Clearly, I have constructed an artificial data set that satisfies the goal of this question.\n",
    "# I constructed a DGP of the form x2=2, with both a systemic separation of +/- 7 based on \n",
    "# the color, and some normally-distributed noise.  The optimal decison boundary should be \n",
    "# described by 1 parm: the mean of 2.\n",
    "# With so few obs, the SVC's estimation will be very imprecise, and thus intuitively we should \n",
    "# lean towards simpler models with more bias and less variance, since variance is such a huge \n",
    "# concern here. Not surprisingly, since we required that the training data be linearly separable, \n",
    "# SVCs with very high values of the cost parameter are able to perfectly separate the two classes \n",
    "# (with significant overfitting), and are indicated as optimal by both the train data (which \n",
    "# doesn't say much) and CV (which is of limited use in this case, with limited data).\n",
    "# However, SVCs with low values of the cost parm choose simpler models and tolerate a few \n",
    "# misclassified values of the training data, and while performing worse on training error and CV on \n",
    "# training data, produce lower test error rates as their parsimony pays off in the long run, \n",
    "# which is what the problem seeks to show."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
