{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 7-12\n",
    "rm(list=ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parms:\n",
    "n <- 200\n",
    "p <- 100\n",
    "n_iter <- 50\n",
    "scale <- 20\n",
    "shift <- 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            temp       temp      temp      temp\n",
      "[1,] 1 -4.689827 -4.6498359  3.177552  6.285035\n",
      "[2,] 1 -2.557522 -5.6270943 -6.298601  8.575545\n",
      "[3,] 1  1.457067  0.3359367  9.087563 -7.050379\n",
      "[4,] 1  8.164156 -4.6209882  7.956970  4.996433\n",
      "[5,] 1 -5.966361 -6.3766335  8.873941  9.513147\n"
     ]
    }
   ],
   "source": [
    "# Create feature data: one matrix with covariates only and a second with intercept appended:\n",
    "set.seed(1)\n",
    "x <- c()\n",
    "for (i in 1:p)\n",
    "{\n",
    "    temp <- (runif(n)*scale-shift)\n",
    "    x <- cbind(x, temp)\n",
    "}\n",
    "# nrow(x); ncol(x)\n",
    "\n",
    "# Append intercept col:\n",
    "x_int <- cbind(matrix(1,nrow=nrow(x),ncol=1), x)\n",
    "print(x_int[1:5,1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create true parms:\n",
    "coef_pool_init <- seq(from=-10, to=10, by=1)\n",
    "# Need to exclude 0 or else it will cause numerical issues with the regression.\n",
    "coef_pool <- coef_pool_init[-11]\n",
    "# Select (p+1) coefficients: for the p features plus the 1 intercept:\n",
    "beta_true <- matrix(sample(coef_pool, p+1, replace=TRUE))\n",
    "# nrow(beta_true); ncol(beta_true)\n",
    "# nrow(x_int); ncol(x_int)\n",
    "\n",
    "# Create response:\n",
    "y <- (x_int %*% beta_true)\n",
    "# nrow(y); ncol(y)\n",
    "# head(y)\n",
    "\n",
    "# Initialize matrix to hold beta estimates after each iteration, and ensure that the parm estimates\n",
    "# chosen for the first iter is different from beta_true:\n",
    "set.seed(2)\n",
    "beta_est <- matrix(sample(coef_pool, p+1, replace=TRUE))\n",
    "# nrow(beta_est); ncol(beta_est)\n",
    "# print(beta_est); print(beta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform backfitting algorithm:\n",
    "beta_storage <- beta_est\n",
    "for (j in 1:n_iter)  \n",
    "{\n",
    "    for (k in 1:p)\n",
    "    {\n",
    "        # Create index var, since 1st var will be int, 2nd var is first feature, etc.\n",
    "        index <- (k+1)\n",
    "        beta_helper <- matrix(beta_est[-c(1,index)], nrow=(p-1), ncol=1)\n",
    "        # First step: offset\n",
    "        y_offset <- (y - x[,-k] %*% beta_helper)\n",
    "        model <- lm(y_offset~x[,k])\n",
    "        # Save coef before the feature in question (this will always be the 2nd coef in a simmple regression):\n",
    "        beta_est[index,1] <- model$coef[2]\n",
    "        # print(beta_est)\n",
    "    }\n",
    "    # Update intercept at the end of each iteration:\n",
    "    beta_est[1,1] <- model$coef[1]\n",
    "    # Save values at end of each iteration:\n",
    "    beta_storage <- cbind(beta_storage, beta_est)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 6 × 51 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>-7</td><td> 14.054528</td><td> 5.2220699</td><td>-1.4241989</td><td>-3.6027597</td><td>-4.843335</td><td>-5.644500</td><td>-6.133595</td><td>-6.405157</td><td>-6.528645</td><td>...</td><td>-6.001036</td><td>-6.000836</td><td>-6.000675</td><td>-6.000546</td><td>-6.000441</td><td>-6.000357</td><td>-6.000288</td><td>-6.000233</td><td>-6.000189</td><td>-6.000153</td></tr>\n",
       "\t<tr><td> 5</td><td>-15.684737</td><td>-7.9271014</td><td>-6.3062204</td><td>-6.8700967</td><td>-7.221194</td><td>-7.432176</td><td>-7.570634</td><td>-7.666060</td><td>-7.736777</td><td>...</td><td>-7.999885</td><td>-7.999908</td><td>-7.999926</td><td>-7.999941</td><td>-7.999953</td><td>-7.999962</td><td>-7.999969</td><td>-7.999975</td><td>-7.999980</td><td>-7.999984</td></tr>\n",
       "\t<tr><td> 2</td><td> -6.242017</td><td>-4.7794825</td><td>-5.3335941</td><td>-6.0066968</td><td>-6.574194</td><td>-7.009888</td><td>-7.319722</td><td>-7.533810</td><td>-7.680075</td><td>...</td><td>-7.999861</td><td>-7.999886</td><td>-7.999906</td><td>-7.999923</td><td>-7.999937</td><td>-7.999948</td><td>-7.999957</td><td>-7.999965</td><td>-7.999971</td><td>-7.999976</td></tr>\n",
       "\t<tr><td>-7</td><td> -5.922028</td><td>-5.6530582</td><td>-5.2351854</td><td>-4.8765126</td><td>-4.478463</td><td>-4.177536</td><td>-3.989112</td><td>-3.881798</td><td>-3.828474</td><td>...</td><td>-3.999536</td><td>-3.999626</td><td>-3.999698</td><td>-3.999757</td><td>-3.999804</td><td>-3.999842</td><td>-3.999872</td><td>-3.999897</td><td>-3.999917</td><td>-3.999933</td></tr>\n",
       "\t<tr><td> 9</td><td>-15.271229</td><td>-9.5018913</td><td>-7.5783403</td><td>-6.9480956</td><td>-6.793465</td><td>-6.794488</td><td>-6.852343</td><td>-6.917578</td><td>-6.969834</td><td>...</td><td>-7.000142</td><td>-7.000114</td><td>-7.000092</td><td>-7.000074</td><td>-7.000060</td><td>-7.000048</td><td>-7.000039</td><td>-7.000031</td><td>-7.000025</td><td>-7.000020</td></tr>\n",
       "\t<tr><td> 9</td><td>  2.612389</td><td>-0.3312846</td><td> 0.3356151</td><td> 0.6102665</td><td> 0.870394</td><td> 1.028555</td><td> 1.113080</td><td> 1.149922</td><td> 1.157915</td><td>...</td><td> 1.000250</td><td> 1.000200</td><td> 1.000160</td><td> 1.000129</td><td> 1.000103</td><td> 1.000083</td><td> 1.000066</td><td> 1.000053</td><td> 1.000043</td><td> 1.000034</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 51 of type dbl\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       "\t -7 &  14.054528 &  5.2220699 & -1.4241989 & -3.6027597 & -4.843335 & -5.644500 & -6.133595 & -6.405157 & -6.528645 & ... & -6.001036 & -6.000836 & -6.000675 & -6.000546 & -6.000441 & -6.000357 & -6.000288 & -6.000233 & -6.000189 & -6.000153\\\\\n",
       "\t  5 & -15.684737 & -7.9271014 & -6.3062204 & -6.8700967 & -7.221194 & -7.432176 & -7.570634 & -7.666060 & -7.736777 & ... & -7.999885 & -7.999908 & -7.999926 & -7.999941 & -7.999953 & -7.999962 & -7.999969 & -7.999975 & -7.999980 & -7.999984\\\\\n",
       "\t  2 &  -6.242017 & -4.7794825 & -5.3335941 & -6.0066968 & -6.574194 & -7.009888 & -7.319722 & -7.533810 & -7.680075 & ... & -7.999861 & -7.999886 & -7.999906 & -7.999923 & -7.999937 & -7.999948 & -7.999957 & -7.999965 & -7.999971 & -7.999976\\\\\n",
       "\t -7 &  -5.922028 & -5.6530582 & -5.2351854 & -4.8765126 & -4.478463 & -4.177536 & -3.989112 & -3.881798 & -3.828474 & ... & -3.999536 & -3.999626 & -3.999698 & -3.999757 & -3.999804 & -3.999842 & -3.999872 & -3.999897 & -3.999917 & -3.999933\\\\\n",
       "\t  9 & -15.271229 & -9.5018913 & -7.5783403 & -6.9480956 & -6.793465 & -6.794488 & -6.852343 & -6.917578 & -6.969834 & ... & -7.000142 & -7.000114 & -7.000092 & -7.000074 & -7.000060 & -7.000048 & -7.000039 & -7.000031 & -7.000025 & -7.000020\\\\\n",
       "\t  9 &   2.612389 & -0.3312846 &  0.3356151 &  0.6102665 &  0.870394 &  1.028555 &  1.113080 &  1.149922 &  1.157915 & ... &  1.000250 &  1.000200 &  1.000160 &  1.000129 &  1.000103 &  1.000083 &  1.000066 &  1.000053 &  1.000043 &  1.000034\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 51 of type dbl\n",
       "\n",
       "| -7 |  14.054528 |  5.2220699 | -1.4241989 | -3.6027597 | -4.843335 | -5.644500 | -6.133595 | -6.405157 | -6.528645 | ... | -6.001036 | -6.000836 | -6.000675 | -6.000546 | -6.000441 | -6.000357 | -6.000288 | -6.000233 | -6.000189 | -6.000153 |\n",
       "|  5 | -15.684737 | -7.9271014 | -6.3062204 | -6.8700967 | -7.221194 | -7.432176 | -7.570634 | -7.666060 | -7.736777 | ... | -7.999885 | -7.999908 | -7.999926 | -7.999941 | -7.999953 | -7.999962 | -7.999969 | -7.999975 | -7.999980 | -7.999984 |\n",
       "|  2 |  -6.242017 | -4.7794825 | -5.3335941 | -6.0066968 | -6.574194 | -7.009888 | -7.319722 | -7.533810 | -7.680075 | ... | -7.999861 | -7.999886 | -7.999906 | -7.999923 | -7.999937 | -7.999948 | -7.999957 | -7.999965 | -7.999971 | -7.999976 |\n",
       "| -7 |  -5.922028 | -5.6530582 | -5.2351854 | -4.8765126 | -4.478463 | -4.177536 | -3.989112 | -3.881798 | -3.828474 | ... | -3.999536 | -3.999626 | -3.999698 | -3.999757 | -3.999804 | -3.999842 | -3.999872 | -3.999897 | -3.999917 | -3.999933 |\n",
       "|  9 | -15.271229 | -9.5018913 | -7.5783403 | -6.9480956 | -6.793465 | -6.794488 | -6.852343 | -6.917578 | -6.969834 | ... | -7.000142 | -7.000114 | -7.000092 | -7.000074 | -7.000060 | -7.000048 | -7.000039 | -7.000031 | -7.000025 | -7.000020 |\n",
       "|  9 |   2.612389 | -0.3312846 |  0.3356151 |  0.6102665 |  0.870394 |  1.028555 |  1.113080 |  1.149922 |  1.157915 | ... |  1.000250 |  1.000200 |  1.000160 |  1.000129 |  1.000103 |  1.000083 |  1.000066 |  1.000053 |  1.000043 |  1.000034 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2]       [,3]       [,4]       [,5]       [,6]      [,7]     \n",
       "[1,] -7    14.054528  5.2220699 -1.4241989 -3.6027597 -4.843335 -5.644500\n",
       "[2,]  5   -15.684737 -7.9271014 -6.3062204 -6.8700967 -7.221194 -7.432176\n",
       "[3,]  2    -6.242017 -4.7794825 -5.3335941 -6.0066968 -6.574194 -7.009888\n",
       "[4,] -7    -5.922028 -5.6530582 -5.2351854 -4.8765126 -4.478463 -4.177536\n",
       "[5,]  9   -15.271229 -9.5018913 -7.5783403 -6.9480956 -6.793465 -6.794488\n",
       "[6,]  9     2.612389 -0.3312846  0.3356151  0.6102665  0.870394  1.028555\n",
       "     [,8]      [,9]      [,10]     [,11] [,12]     [,13]     [,14]    \n",
       "[1,] -6.133595 -6.405157 -6.528645 ...   -6.001036 -6.000836 -6.000675\n",
       "[2,] -7.570634 -7.666060 -7.736777 ...   -7.999885 -7.999908 -7.999926\n",
       "[3,] -7.319722 -7.533810 -7.680075 ...   -7.999861 -7.999886 -7.999906\n",
       "[4,] -3.989112 -3.881798 -3.828474 ...   -3.999536 -3.999626 -3.999698\n",
       "[5,] -6.852343 -6.917578 -6.969834 ...   -7.000142 -7.000114 -7.000092\n",
       "[6,]  1.113080  1.149922  1.157915 ...    1.000250  1.000200  1.000160\n",
       "     [,15]     [,16]     [,17]     [,18]     [,19]     [,20]     [,21]    \n",
       "[1,] -6.000546 -6.000441 -6.000357 -6.000288 -6.000233 -6.000189 -6.000153\n",
       "[2,] -7.999941 -7.999953 -7.999962 -7.999969 -7.999975 -7.999980 -7.999984\n",
       "[3,] -7.999923 -7.999937 -7.999948 -7.999957 -7.999965 -7.999971 -7.999976\n",
       "[4,] -3.999757 -3.999804 -3.999842 -3.999872 -3.999897 -3.999917 -3.999933\n",
       "[5,] -7.000074 -7.000060 -7.000048 -7.000039 -7.000031 -7.000025 -7.000020\n",
       "[6,]  1.000129  1.000103  1.000083  1.000066  1.000053  1.000043  1.000034"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(beta_storage)\n",
    "# Clearly more iterations are necessary to obtain a \"good\" approximation to the multiple regression estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple regression\n",
    "mult <- lm(y~x)\n",
    "# summary(mult)\n",
    "# Results are essentially the same as beta_true, so I'll use that.\n",
    "# Here I compute the 2-norm between each iter and beta_true:\n",
    "two_norm <- matrix(0, nrow=n_iter, ncol=1)\n",
    "for (i in 1:n_iter)\n",
    "{\n",
    "    two_norm[i,1] <- sqrt(sum((beta_storage[,(i+1)]-beta_true)^2))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\n0R6mSwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      },
      "text/plain": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot:\n",
    "plot(1:n_iter, two_norm, xlab=\"Iteration Number\", ylab=\"Distance\")\n",
    "# Qualitatively speaking, it takes about 10 iterations in order to obtain a \"good approximation\" of beta_true.\n",
    "# I imagine this is due in part to the fact we had so many more (100) features, rather than just two."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
